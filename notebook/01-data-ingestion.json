{
	"name": "01-data-ingestion",
	"properties": {
		"nbformat": 4,
		"nbformat_minor": 2,
		"bigDataPool": {
			"referenceName": "sparkpool",
			"type": "BigDataPoolReference"
		},
		"sessionProperties": {
			"driverMemory": "28g",
			"driverCores": 4,
			"executorMemory": "28g",
			"executorCores": 4,
			"numExecutors": 2,
			"conf": {
				"spark.dynamicAllocation.enabled": "false",
				"spark.dynamicAllocation.minExecutors": "2",
				"spark.dynamicAllocation.maxExecutors": "2",
				"spark.autotune.trackingId": "04fbe8b9-1f3c-4416-b2c5-b0c951e49f37"
			}
		},
		"metadata": {
			"saveOutput": true,
			"enableDebugMode": false,
			"kernelspec": {
				"name": "synapse_pyspark",
				"display_name": "Synapse PySpark"
			},
			"language_info": {
				"name": "python"
			},
			"a365ComputeOptions": {
				"id": "/subscriptions/98fb3285-f648-4b06-80a4-01c259978e8f/resourceGroups/flights-mlops-proof-of-concept/providers/Microsoft.Synapse/workspaces/synw-flights-bronze-layer/bigDataPools/sparkpool",
				"name": "sparkpool",
				"type": "Spark",
				"endpoint": "https://synw-flights-bronze-layer.dev.azuresynapse.net/livyApi/versions/2019-11-01-preview/sparkPools/sparkpool",
				"auth": {
					"type": "AAD",
					"authResource": "https://dev.azuresynapse.net"
				},
				"sparkVersion": "3.3",
				"nodeCount": 3,
				"cores": 4,
				"memory": 28,
				"automaticScaleJobs": false
			},
			"sessionKeepAliveTimeout": 30
		},
		"cells": [
			{
				"cell_type": "code",
				"source": [
					"from pyspark.sql import SparkSession\r\n",
					"from pyspark.sql.types import StringType, IntegerType, DoubleType, StructType, StructField\r\n",
					"from datetime import datetime, timedelta\r\n",
					"import uuid\r\n",
					"import random\r\n",
					"\r\n",
					"# Date range from 2023-07-01 to 2024-07-01\r\n",
					"start_date = datetime(2023, 7, 1)\r\n",
					"end_date = datetime(2024, 7, 1)\r\n",
					"date_range = [start_date + timedelta(days=i) for i in range((end_date - start_date).days)]\r\n",
					"\r\n",
					"# Providers\r\n",
					"providers = [\r\n",
					"    \"TRAVELFUSION/americanAirlines\", \"AMADEUS/voyzant\", \"AMADEUS/picasso\",\r\n",
					"    \"AMADEUS/aerticket\", \"AMADEUS/amadeus\", \"TRAVELFUSION/lufthansa\", \"TRAVELFUSION/travelfusion\"\r\n",
					"]\r\n",
					"\r\n",
					"# Routes\r\n",
					"routes = [\r\n",
					"    'EWR-CAI', 'FLL-LIS', 'JFK-ATH', 'JFK-CAI', 'LAX-ATH', 'LGA-CAI', 'LGW-IST', 'LGW-NRT', 'LHR-AMM',\r\n",
					"    'LHR-DEL', 'LHR-HND', 'LHR-IST', 'LHR-LIM', 'LHR-NRT', 'LHR-SAW', 'MIA-LIS', 'STN-AMM', 'STN-SAW',\r\n",
					"    'YTZ-ATH', 'YTZ-LIS', 'YYZ-ATH', 'YYZ-JNB', 'YYZ-LIS', 'JFK-JNB', 'YYZ-UIO', 'LAX-JNB', 'LHR-JNB',\r\n",
					"    'LHR-SJO', 'SFO-LIS', 'YUL-LIS', 'LAX-LIM', 'YYZ-LIM', 'LAX-LIS', 'MIA-LIM', 'LAX-IST', 'LAX-UIO'\r\n",
					"]\r\n",
					"\r\n",
					"# Currencies\r\n",
					"currencies = [\r\n",
					"    \"EUR\", \"COP\", \"MXN\", \"USD\", \"CAD\", \"GBP\"\r\n",
					"]\r\n",
					"\r\n",
					"baggage = [\r\n",
					"    \"0PC\", \"1PC\", \"2PC\", \"3PC\"\r\n",
					"]\r\n",
					"\r\n",
					"# Function to generate rows in PySpark DataFrame format\r\n",
					"def generate_rows_for_date(date):\r\n",
					"    num_rows = random.randint(100000, 150000)  # Generate between 100,000 to 150,000 rows per day\r\n",
					"    rows = []\r\n",
					"    for _ in range(num_rows):\r\n",
					"        total_person = random.randint(1, 5)\r\n",
					"        total_flight_cost = random.uniform(21.23, 1043391124.4)\r\n",
					"        total_flight_cost_per_passenger = total_flight_cost / total_person\r\n",
					"        rows.append((\r\n",
					"            str(uuid.uuid4()),                                               # id\r\n",
					"            f\"L1{{{random.choice(routes)}}}_L2{random.randint(1000, 9999)}1PC\",  # flight_code\r\n",
					"            f\"flightHistory/{date.strftime('%Y-%m-%d')}/{uuid.uuid4().hex}.json.gz\",  # file_path\r\n",
					"            random.choice(providers),                                         # source\r\n",
					"            date.strftime(\"%Y-%m-%d\"),                                         # search_date\r\n",
					"            (date + timedelta(days=10, hours=10, minutes=25)).strftime(\"%Y-%m-%d %H:%M:%S\"),  # outbound_departure_datetime\r\n",
					"            (date + timedelta(days=15, hours=10, minutes=25)).strftime(\"%Y-%m-%d %H:%M:%S\"),  # inbound_departure_datetime\r\n",
					"            random.choice(routes),                                            # route\r\n",
					"            \"BUE\",                                                            # city_pair\r\n",
					"            \"AR\",                                                             # country\r\n",
					"            \"CAB_ECONOMY\",                                                    # cabin_class\r\n",
					"            \"AEP\",                                                            # airport_code\r\n",
					"            \"publishedFare\",                                                  # fare_type\r\n",
					"            total_person,                                                     # passengers\r\n",
					"            random.randint(0, 1),                                              # infants\r\n",
					"            random.randint(0, 2),                                              # children\r\n",
					"            total_person,                                                     # adults\r\n",
					"            random.choice(currencies),                                                            # currency\r\n",
					"            total_flight_cost,                                                # total_cost\r\n",
					"            total_flight_cost_per_passenger,                                  # cost_per_adult\r\n",
					"            random.choice(baggage),                                                            # baggage_allowance\r\n",
					"            date.strftime(\"%Y-%m-%d %H:%M:%S\")                                # last_update\r\n",
					"        ))\r\n",
					"    return rows\r\n",
					"\r\n",
					"# Create list of rows for all dates\r\n",
					"all_rows = []\r\n",
					"for date in date_range:\r\n",
					"    all_rows.extend(generate_rows_for_date(date))\r\n",
					"\r\n",
					"# Create RDD from all_rows\r\n",
					"rdd = spark.sparkContext.parallelize(all_rows)\r\n",
					"\r\n",
					"# Create DataFrame schema\r\n",
					"schema = StructType([\r\n",
					"    StructField(\"id\", StringType(), True),\r\n",
					"    StructField(\"flight_code\", StringType(), True),\r\n",
					"    StructField(\"file_path\", StringType(), True),\r\n",
					"    StructField(\"source\", StringType(), True),\r\n",
					"    StructField(\"search_date\", StringType(), True),\r\n",
					"    StructField(\"outbound_departure_datetime\", StringType(), True),\r\n",
					"    StructField(\"inbound_departure_datetime\", StringType(), True),\r\n",
					"    StructField(\"route\", StringType(), True),\r\n",
					"    StructField(\"city_pair\", StringType(), True),\r\n",
					"    StructField(\"country\", StringType(), True),\r\n",
					"    StructField(\"cabin_class\", StringType(), True),\r\n",
					"    StructField(\"airport_code\", StringType(), True),\r\n",
					"    StructField(\"fare_type\", StringType(), True),\r\n",
					"    StructField(\"passengers\", IntegerType(), True),\r\n",
					"    StructField(\"infants\", IntegerType(), True),\r\n",
					"    StructField(\"children\", IntegerType(), True),\r\n",
					"    StructField(\"adults\", IntegerType(), True),\r\n",
					"    StructField(\"currency\", StringType(), True),\r\n",
					"    StructField(\"total_cost\", DoubleType(), True),\r\n",
					"    StructField(\"cost_per_adult\", DoubleType(), True),\r\n",
					"    StructField(\"baggage_allowance\", StringType(), True),\r\n",
					"    StructField(\"last_update\", StringType(), True)\r\n",
					"])\r\n",
					"\r\n",
					"# Create DataFrame from RDD applying the schema\r\n",
					"df = spark.createDataFrame(rdd, schema=schema)\r\n",
					"\r\n",
					"# Display sample data\r\n",
					"df.show()\r\n",
					""
				],
				"execution_count": null
			}
		]
	}
}